# -*- coding: utf-8 -*-
"""OneYes Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BbPqG0jbAOBGdTAG4XburH5obVKH5dlR
"""

import pandas as pd
import numpy as np

# Load dataset
df = pd.read_csv("/content/supply_chain_fully_unclean.csv")
print(df.info())

df.head()

"""## Data Cleaning

"""

# Convert date column
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

# Convert numeric columns
numeric_columns = [
    'Units_Sold', 'Inventory_Level', 'Supplier_Lead_Time_Days',
    'Reorder_Point', 'Order_Quantity', 'Unit_Cost', 'Unit_Price',
    'Demand_Forecast'
]
for col in numeric_columns:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# --- STEP 2: HANDLE MISSING VALUES ---
# Numeric columns → fill with median
for col in numeric_columns:
    if col in df.columns:
        df[col].fillna(df[col].median(), inplace=True)

# Categorical columns → fill with mode
categorical_columns = df.select_dtypes(include='object').columns
for col in categorical_columns:
    df[col] = df[col].fillna(df[col].mode()[0])

# --- STEP 3: REMOVE DUPLICATES ---
df.drop_duplicates(inplace=True)

# --- STEP 4: REMOVE OUTLIERS FROM UNITS_SOLD ---
if 'Units_Sold' in df.columns:
    upper_limit = df['Units_Sold'].quantile(0.99)
    df = df[df['Units_Sold'] <= upper_limit]

# --- STEP 5: STRIP & LOWERCASE TEXT FIELDS ---
for col in categorical_columns:
    df[col] = df[col].astype(str).str.strip().str.lower()

# --- STEP 6: CALCULATE SAFETY STOCK ---
Z = 1.65  # 95% service level
if 'SKU_ID' in df.columns and 'Units_Sold' in df.columns:
    demand_std = df.groupby('SKU_ID')['Units_Sold'].transform('std').fillna(0)
    df['Safety_Stock'] = Z * demand_std * np.sqrt(df['Supplier_Lead_Time_Days'])

# --- STEP 7: CALCULATE OPENING & CLOSING STOCK ---
df = df.sort_values(['SKU_ID', 'Date'])
df['Opening_Stock'] = df.groupby('SKU_ID')['Inventory_Level'].shift(1)
df['Opening_Stock'].fillna(df['Inventory_Level'], inplace=True)
df['Closing_Stock'] = df['Opening_Stock'] - df['Units_Sold'] + df['Order_Quantity']

# --- STEP 8: CALCULATE FULFILLMENT RATE ---
df['Fulfillment_Rate'] = (df['Units_Sold'] / df['Demand_Forecast']).clip(upper=1)

# --- STEP 9: FLAG PERISHABLE PRODUCTS (SIMULATED) ---
np.random.seed(42)
df['Perishable_Flag'] = np.random.choice([0, 1], size=len(df), p=[0.7, 0.3])

# --- STEP 10: RECOMPUTE STOCKOUT FLAG ---
df['Stockout_Flag'] = np.where(df['Inventory_Level'] <= 0, 1, 0)

# --- STEP 11: EXPORT CLEANED DATASET ---
df.to_csv("/content/supply_chain_enriched.csv", index=False)
print("Cleaned and enriched dataset saved.")

"""# UNCLEANED DATASET Vs CLEANED DATASET"""

import pandas as pd

# Load datasets
uncleaned_df = pd.read_csv("/content/supply_chain_fully_unclean.csv")
cleaned_df = pd.read_csv("/content/supply_chain_enriched.csv")

# 1. SHAPE DIFFERENCE
print(" Shape Comparison")
print(f"Uncleaned Dataset Shape: {uncleaned_df.shape}")
print(f"Cleaned Dataset Shape:   {cleaned_df.shape}")
print()

# 2. COLUMN DIFFERENCES
print(" Column Comparison")
print("Columns only in Uncleaned Dataset:")
print(set(uncleaned_df.columns) - set(cleaned_df.columns))

print("\nColumns only in Cleaned Dataset:")
print(set(cleaned_df.columns) - set(uncleaned_df.columns))
print()

# 3. NULL VALUE COMPARISON
print(" Null Value Summary (Top 10 columns)")
null_summary = pd.DataFrame({
    'Uncleaned': uncleaned_df.isnull().sum(),
    'Cleaned': cleaned_df.isnull().sum()
})
print(null_summary.sort_values('Uncleaned', ascending=False).head(10))
print()

# 4. SAMPLE ROWS FOR VISUAL COMPARISON
print(" Preview of Uncleaned Dataset:")
print(uncleaned_df.head(2))
print("\n Preview of Cleaned Dataset:")
print(cleaned_df.head(2))

"""# Exploratory Data Analysis"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

plt.figure(figsize=(8, 5))
sns.histplot(df['Units_Sold'], bins=30, kde=True)
plt.title('Distribution of Units Sold')
plt.xlabel('Units Sold')
plt.ylabel('Frequency')
plt.show()

if 'Fulfillment_Rate' in df.columns:
    print("\nAverage Fulfillment Rate per Warehouse:")
    print(df.groupby('Warehouse_ID')['Fulfillment_Rate'].mean().sort_values())

"""# Machine Learning"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

features = ['Units_Sold', 'Demand_Forecast', 'Inventory_Level', 'Promotion_Flag',
            'Warehouse_ID', 'Region', 'Perishable_Flag', 'Unit_Price']
target = 'Fulfillment_Rate'

df_encoded = pd.get_dummies(df[features], drop_first=True)

df_model = df_encoded.copy()
df_model[target] = df[target]
df_model.dropna(inplace=True)

X = df_model.drop(columns=target)
y = df_model[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

rmse, r2